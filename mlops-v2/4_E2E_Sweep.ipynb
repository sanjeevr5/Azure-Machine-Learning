{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "246e951c-3854-4858-a0a6-c7c9207407b2",
   "metadata": {},
   "source": [
    "# IRIS data training with Sweep (Hyper param tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716a90e7-8c7d-42d6-b856-b8180671d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptionID = '80ea84e8-afce-4851-928a-9e2219724c69'\n",
    "RG = '1-baef76e5-playground-sandbox'\n",
    "ws_name = \"MLOPS101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee06f862-5957-4133-a1da-205253d11a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7fdace8b4d90>,\n",
      "         subscription_id=80ea84e8-afce-4851-928a-9e2219724c69,\n",
      "         resource_group_name=1-baef76e5-playground-sandbox,\n",
      "         workspace_name=MLOPS101)\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "ws = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    subscription_id = subscriptionID,\n",
    "    resource_group_name = RG,\n",
    "    workspace_name= ws_name,\n",
    ")\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7694a9-3f19-4877-84c9-97bf95c23367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with name raw_iris_data was registered to workspace, the dataset version is 1.0.0\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "iris_url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
    "\n",
    "iris_data = Data(\n",
    "    name = \"raw_iris_data\",\n",
    "    path = iris_url,\n",
    "    type = AssetTypes.URI_FILE,\n",
    "    description = \"Uncleansed IRIS dataset\",\n",
    "    tags = {\"source_type\": \"web\"},\n",
    "    version = \"1.0.0\",\n",
    ") #Stores in the default datastore\n",
    "\n",
    "iris_data = ws.data.create_or_update(iris_data)\n",
    "print(f\"Dataset with name {iris_data.name} was registered to workspace, the dataset version is {iris_data.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f21bef2-2feb-4b31-8e29-4b9c517728d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new cpu compute target...\n",
      "Cluster created successfully named iris-cluster with size STANDARD_D2_V2\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "\n",
    "def createCluster(cluster_name, size):\n",
    "    try:\n",
    "        cpu_cluster = ws.compute.get(cluster_name)\n",
    "        print(f'{CLUSTER_NAME} exists!')\n",
    "    except Exception:\n",
    "        print(\"Creating a new cpu compute target...\")\n",
    "        cpu_cluster = AmlCompute(\n",
    "            name=cluster_name,\n",
    "            type=\"amlcompute\",\n",
    "            size=size,\n",
    "            min_instances=0,\n",
    "            max_instances=1,\n",
    "            idle_time_before_scale_down=180,\n",
    "            tier=\"Dedicated\",\n",
    "        )\n",
    "        cpu_cluster = ws.compute.begin_create_or_update(cpu_cluster).result()\n",
    "        print(f'Cluster created successfully named {cpu_cluster.name} with size {cpu_cluster.size}')\n",
    "    return cpu_cluster\n",
    "\n",
    "CLUSTER_NAME = 'iris-cluster'\n",
    "CLUSTER_SIZE = 'Standard_D2_v2'\n",
    "\n",
    "trainCluster = createCluster(CLUSTER_NAME, CLUSTER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d272cff6-9c15-4cef-84ad-4a579b25e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PARENT_DIR = Path(\"./E2EPipelines\")\n",
    "ENVIRONMENT_DIR = PARENT_DIR / \"environment\"\n",
    "TRAIN_DIR = PARENT_DIR / \"train\"\n",
    "PREDICT_DIR = PARENT_DIR / \"predict\"\n",
    "\n",
    "ENVIRONMENT_DIR.mkdir(parents = True, exist_ok = True)\n",
    "TRAIN_DIR.mkdir(parents = True, exist_ok = True)\n",
    "PREDICT_DIR.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0852ae59-91a9-4ea2-ae08-7b484819df38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing E2EPipelines/environment/conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {ENVIRONMENT_DIR}/conda.yaml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scikit-learn=0.24.2\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow== 1.26.1\n",
    "    - azureml-mlflow==1.42.0\n",
    "    - matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1c6b10-8e4f-4b4e-b0e6-36bda84623ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name iris-env is registered to workspace, the environment version is 0.2.0\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"iris-env\"\n",
    "\n",
    "iris_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for IRIS data\",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file = 'E2EPipelines/environment/conda.yaml',\n",
    "    image = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.2.0\",\n",
    ")\n",
    "iris_env = ws.environments.create_or_update(iris_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {iris_env.name} is registered to workspace, the environment version is {iris_env.version}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca4c1a84-fed2-46b7-bef7-ac9dd10558cd",
   "metadata": {},
   "source": [
    "## Training components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1221a9cf-10dc-4042-ac1c-e1af249a19c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing E2EPipelines/train/train.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAIN_DIR}/train.yml\n",
    "\n",
    "name: iris_train\n",
    "display_name: IRIS Train Config\n",
    "type: command\n",
    "inputs:\n",
    "    raw_data:\n",
    "        type: uri_file\n",
    "    split_ratio:\n",
    "        type: number\n",
    "        default: 0.7\n",
    "    max_depth:\n",
    "        type: number\n",
    "        default: 3\n",
    "outputs:\n",
    "    model_output:\n",
    "        type: mlflow_model\n",
    "    test_data:\n",
    "        type: uri_folder\n",
    "code: ./train.py\n",
    "environment: azureml:iris-env:0.2.0\n",
    "command: >-\n",
    "    python train.py\n",
    "    --raw_data ${{inputs.raw_data}}\n",
    "    --split_ratio ${{inputs.split_ratio}}\n",
    "    --max_depth ${{inputs.max_depth}}\n",
    "    --model_output ${{outputs.model_output}}\n",
    "    --test_data ${{outputs.test_data}}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873a7d0e-a96a-4f26-b6ee-79d0ec587295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing E2EPipelines/train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAIN_DIR}/train.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "def parseArgs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--raw_data', type = str)\n",
    "    parser.add_argument('--split_ratio', type = float, default = 0.8)\n",
    "    parser.add_argument('--max_depth', type = int, default = 3)\n",
    "    parser.add_argument('--model_output', type = str, help = 'Model saved in this path')\n",
    "    parser.add_argument('--test_data', type = str, help = 'X_train and y_train are stored here')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "    \n",
    "\n",
    "def main(args):\n",
    "    mlflow.autolog()\n",
    "    params = {\n",
    "        'max_depth' : args.max_depth\n",
    "    }\n",
    "    df = pd.read_csv(args.raw_data)\n",
    "    train, test = train_test_split(df, train_size = args.split_ratio, random_state = 42, stratify = df.variety)\n",
    "    y_train, y_test = train.pop('variety'), test.pop('variety')\n",
    "    \n",
    "    mlflow.log_param('Train size', train.shape)\n",
    "    mlflow.log_param('Test size', test.shape)\n",
    "    \n",
    "    model = DecisionTreeClassifier(**params)\n",
    "    model.fit(train, y_train)\n",
    "    mlflow.sklearn.save_model(model, 'model')\n",
    "    copy_tree('model', args.model_output)\n",
    "    \n",
    "    test.to_csv(Path(args.test_data) / \"X_test.csv\", index=False)\n",
    "    y_test.to_csv(Path(args.test_data) / \"y_test.csv\", index=False)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    args = parseArgs()\n",
    "    main(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26621c2d-841e-43e1-a177-af707bd35362",
   "metadata": {},
   "source": [
    "## Prediction scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bb0b90-4734-45bd-acb3-4e63cc8d63b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing E2EPipelines/predict/predict.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PREDICT_DIR}/predict.yml\n",
    "\n",
    "name: iris_predict\n",
    "display_name: IRIS Predict Config\n",
    "type: command\n",
    "inputs:\n",
    "    model:\n",
    "        type: mlflow_model\n",
    "    test_data:\n",
    "        type: uri_folder \n",
    "outputs:\n",
    "    predictions:\n",
    "        type: uri_folder\n",
    "code: ./predict.py\n",
    "environment: azureml:iris-env:0.2.0  \n",
    "command: >-\n",
    "    python predict.py\n",
    "    --model ${{inputs.model}}\n",
    "    --test_data ${{inputs.test_data}}\n",
    "    --predictions ${{outputs.predictions}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d580aea-1cee-4838-8fff-244569adf016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting E2EPipelines/predict/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PREDICT_DIR}/predict.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type = str)\n",
    "parser.add_argument('--test_data', type = str)\n",
    "parser.add_argument('--predictions', type = str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "X_test = pd.read_csv(Path(args.test_data) / 'X_test.csv')\n",
    "\n",
    "model = mlflow.sklearn.load_model(Path(args.model))\n",
    "\n",
    "mlflow.sklearn.log_model(\n",
    "    sk_model = model,\n",
    "    registered_model_name = \"irisbest\",\n",
    "    artifact_path = args.model,\n",
    ")\n",
    "\n",
    "y_test = pd.read_csv(Path(args.test_data) / 'y_test.csv')\n",
    "y_test['predict'] = model.predict(X_test)\n",
    "y_test.to_csv(Path(args.predictions) / 'predict_result.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbd122cc-ed8a-4649-ac70-ba12d0b17a97",
   "metadata": {},
   "source": [
    "## Pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4128a2fd-4dde-4b08-b112-2e0b53d7d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input, Output, load_component\n",
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "train_component_func = load_component(source = TRAIN_DIR / 'train.yml')\n",
    "score_component_func = load_component(source = PREDICT_DIR / 'predict.yml')\n",
    "\n",
    "@dsl.pipeline(compute = trainCluster, description = 'Iris Sweep Job')\n",
    "def irisSweepPipeline():\n",
    "    \n",
    "    raw_data = Input(type = 'uri_file', path = iris_data.path)\n",
    "    train_model = train_component_func(raw_data = raw_data,\n",
    "                                       split_ratio = 0.8,\n",
    "                                       max_depth = Choice([2, 3]))\n",
    "    sweep_step = train_model.sweep(\n",
    "        primary_metric = 'training_f1_score',\n",
    "        goal = 'maximize',\n",
    "        sampling_algorithm = 'random',\n",
    "    )\n",
    "    sweep_step.set_limits(max_total_trials = 2, max_concurrent_trials = 2, timeout = 7200)\n",
    "    score_data = score_component_func(\n",
    "       model = sweep_step.outputs.model_output, test_data=sweep_step.outputs.test_data\n",
    "    )\n",
    "    return {'model_dir' : sweep_step.outputs.model_output}\n",
    "\n",
    "pipeline_job = irisSweepPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4228a5a7-5492-4fa2-95e9-882971613ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading predict.py\u001b[32m (< 1 MB): 100%|██████████| 750/750 [00:00<00:00, 69.1kB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>Iris With Sweep</td><td>amusing_queen_hdl8tytzwx</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/amusing_queen_hdl8tytzwx?wsid=/subscriptions/80ea84e8-afce-4851-928a-9e2219724c69/resourcegroups/1-baef76e5-playground-sandbox/workspaces/MLOPS101&amp;tid=84f1e4ea-8554-43e1-8709-f0b8589ea118\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {'model_dir': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7fda8753ae30>}, 'jobs': {}, 'component': PipelineComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'name': 'azureml_anonymous', 'description': 'Iris Sweep Job', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops101/code/Users/cloud_user_p_7a18f760', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fda87442410>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'irisSweepPipeline', 'is_deterministic': None, 'inputs': {}, 'outputs': {'model_dir': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'sweep_step': Sweep({'job_inputs': {'raw_data': {'type': 'uri_file', 'path': 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'}, 'split_ratio': '0.8'}, 'job_outputs': {'model_output': '${{parent.outputs.model_dir}}'}, 'init': False, 'type': 'sweep', 'status': None, 'log_files': None, 'name': 'sweep_step', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops101/code/Users/cloud_user_p_7a18f760', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fda87442aa0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'inputs': {'raw_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fda87442980>, 'split_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fda87442a40>}, 'outputs': {'model_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fda87442a70>}, 'component': 'azureml_anonymous:63464684-e33a-4f19-a58f-bb50643dc4ed', 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': 'b4e04b37-3465-4901-99f8-d976c1f0cdfb', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'sampling_algorithm': 'random', 'early_termination': None, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7fda874421d0>, 'search_space': {'max_depth': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7fda874420b0>}, 'queue_settings': None, 'objective': <azure.ai.ml.entities._job.sweep.objective.Objective object at 0x7fda874426e0>, 'identity': None}), 'score_data': Command({'parameters': {}, 'init': False, 'type': 'command', 'status': None, 'log_files': None, 'name': 'score_data', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops101/code/Users/cloud_user_p_7a18f760', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fda87442ad0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'model': '${{parent.jobs.sweep_step.outputs.model_output}}', 'test_data': '${{parent.jobs.sweep_step.outputs.test_data}}'}, 'job_outputs': {}, 'inputs': {'model': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fda874429e0>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fda874429b0>}, 'outputs': {}, 'component': 'azureml_anonymous:be52af59-8008-4846-8b52-f9f0706976c2', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '1aa19e14-7ce3-4d53-9903-98911eeb52fe', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'sweep': 1, 'command': 1}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 2}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'amusing_queen_hdl8tytzwx', 'description': 'Iris Sweep Job', 'tags': {}, 'properties': {'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'iris-cluster', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/80ea84e8-afce-4851-928a-9e2219724c69/resourceGroups/1-baef76e5-playground-sandbox/providers/Microsoft.MachineLearningServices/workspaces/MLOPS101/jobs/amusing_queen_hdl8tytzwx', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops101/code/Users/cloud_user_p_7a18f760', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fda87442260>, 'serialize': <msrest.serialization.Serializer object at 0x7fda87539db0>, 'display_name': 'irisSweepPipeline', 'experiment_name': 'Iris With Sweep', 'compute': 'iris-cluster', 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7fda874428f0>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7fda874428c0>}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job = ws.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name = \"Iris With Sweep\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62aafcde-a7cd-4297-a0e8-c4ef1700fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: amusing_queen_hdl8tytzwx\n",
      "Web View: https://ml.azure.com/runs/amusing_queen_hdl8tytzwx?wsid=/subscriptions/80ea84e8-afce-4851-928a-9e2219724c69/resourcegroups/1-baef76e5-playground-sandbox/workspaces/MLOPS101\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2023-06-03 13:39:44Z] Completing processing run id 2fe2a893-1558-44bd-a25b-568d244510e8.\n",
      "[2023-06-03 13:39:44Z] Submitting 1 runs, first five are: 1733a49f:e408e5b7-5651-4097-a888-6650a52cd0e0\n",
      "[2023-06-03 13:40:34Z] Completing processing run id e408e5b7-5651-4097-a888-6650a52cd0e0.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: amusing_queen_hdl8tytzwx\n",
      "Web View: https://ml.azure.com/runs/amusing_queen_hdl8tytzwx?wsid=/subscriptions/80ea84e8-afce-4851-928a-9e2219724c69/resourcegroups/1-baef76e5-playground-sandbox/workspaces/MLOPS101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
