{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e8c805-e7da-44ef-8470-b766c03740c3",
   "metadata": {},
   "source": [
    "# Deploying a model + custom transformer on Managed Online Endpoint (MOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abcf14ba-0df9-4a0b-b65e-127ba16030d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptionID = '0cfe2870-d256-4119-b0a3-16293ac11bdc'\n",
    "RG = '1-2ba149fb-playground-sandbox'\n",
    "ws_name = \"MLOPS101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85f3056-9cb2-4634-91af-d840bc42b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7fb715dea5c0>,\n",
      "         subscription_id=0cfe2870-d256-4119-b0a3-16293ac11bdc,\n",
      "         resource_group_name=1-2ba149fb-playground-sandbox,\n",
      "         workspace_name=MLOPS101)\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "ws = MLClient(DefaultAzureCredential(), subscription_id = subscriptionID,\n",
    "              resource_group_name = RG, workspace_name = ws_name)\n",
    "\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de67ea13-2c44-41f3-8f42-c08faa1e6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-16 07:56:41--  https://raw.githubusercontent.com/Azure/azureml-examples/main/sdk/python/endpoints/batch/deploy-pipelines/training-with-components/data/train/heart.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13273 (13K) [text/plain]\n",
      "Saving to: ‘assets/data/heart.csv’\n",
      "\n",
      "heart.csv           100%[===================>]  12.96K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-06-16 07:56:41 (1.22 MB/s) - ‘assets/data/heart.csv’ saved [13273/13273]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Azure/azureml-examples/main/sdk/python/endpoints/batch/deploy-pipelines/training-with-components/data/train/heart.csv -P assets/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ebce642-5485-4dd3-a7c8-81050cf83291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path('./assets')\n",
    "ENV_DIR = ROOT_DIR / 'env'\n",
    "TRAIN_DIR = ROOT_DIR / 'train'\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "DEPLOYMENT_DIR = ROOT_DIR / 'deployment'\n",
    "\n",
    "ENV_DIR.mkdir(parents = True, exist_ok = True)\n",
    "TRAIN_DIR.mkdir(parents = True, exist_ok = True)\n",
    "DATA_DIR.mkdir(parents = True, exist_ok = True)\n",
    "DEPLOYMENT_DIR.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0505ea95-4c25-4413-ba05-bd00b90c966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./assets/train/col_transformer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "transform_filename = 'column_transformer.pkl'\n",
    "continuous_features = ['age', 'chol', 'oldpeak', 'thalach', 'trestbps']\n",
    "discrete_features = ['ca', 'cp', 'exang', 'fbs', 'restecg', 'sex', 'slope', 'thal']\n",
    "target_column = 'target'\n",
    "\n",
    "def preprocessing_pipeline(categorical_encoding, cf, df): #cf -> Continuous feat df -> discrete feat\n",
    "    try:\n",
    "        if categorical_encoding == 'ordinal':\n",
    "            cat_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "        elif categorical_encoding == 'onehot':\n",
    "            cat_enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        else:\n",
    "            raise NotImplementedError('Possible values are ordinal or onehot')\n",
    "\n",
    "        conti_feat_pipeline = sklearn.pipeline.Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy = 'median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        disc_feat_pipeline = sklearn.pipeline.Pipeline([\n",
    "\n",
    "            ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "            ('encoder', cat_enc)\n",
    "\n",
    "        ])\n",
    "\n",
    "        transformations = ColumnTransformer([\n",
    "            ('conti_feat_pipeline', conti_feat_pipeline, cf),\n",
    "            ('disc_feat_pipeline', disc_feat_pipeline, df)\n",
    "        ])\n",
    "        return transformations\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno, e)\n",
    "\n",
    "def preprocess_data(dataframe, label, cf, df, cat_enc = 'ordinal', transformations = None):\n",
    "    try:\n",
    "    \n",
    "        if label in dataframe.columns:\n",
    "            X = dataframe.iloc[:,:-1]\n",
    "            restore_target = True\n",
    "        else:\n",
    "            X = dataframe\n",
    "            restore_target = False\n",
    "\n",
    "        if transformations:\n",
    "            X_transformed = transformations.transform(X)\n",
    "        else:\n",
    "            transformations = preprocessing_pipeline(cat_enc, cf, df)\n",
    "            X_transformed = transformations.fit_transform(X)\n",
    "        transformed_discrete_features = (\n",
    "            transformations.transformers_[1][1]\n",
    "            .named_steps[\"encoder\"]\n",
    "            .get_feature_names_out(discrete_features)\n",
    "        )\n",
    "        all_features = continuous_features + list(transformed_discrete_features)\n",
    "\n",
    "        if restore_target:\n",
    "            target_values = dataframe[label].to_numpy().reshape(len(dataframe), 1)\n",
    "            X_transformed = np.hstack((X_transformed, target_values))\n",
    "            all_features.append(label)\n",
    "\n",
    "        return pd.DataFrame(X_transformed, columns = all_features), transformations\n",
    "    \n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno, e)\n",
    "\n",
    "temp = pd.read_csv('./assets/data/heart.csv')\n",
    "preprocessed, transformations = preprocess_data(\n",
    "    temp,\n",
    "    target_column,\n",
    "    continuous_features,\n",
    "    discrete_features,\n",
    "    'ordinal'\n",
    ")\n",
    "preprocessed.to_csv('./assets/data/transformed_heart.csv', index=False)\n",
    "joblib.dump(transformations, './assets/train/col_transformer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378642bc-2d73-4185-b978-58af5f683ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7868852459016393, 'recall': 0.625}\n"
     ]
    }
   ],
   "source": [
    "from distutils.util import strtobool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('./assets/data/transformed_heart.csv')\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "train_features = train.drop(columns=[target_column])\n",
    "train_target = train[target_column]\n",
    "\n",
    "model = XGBClassifier(scale_pos_weight=99)\n",
    "model.fit(train_features, train_target)\n",
    "\n",
    "test_features = test.drop(columns=[target_column])\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "test['Labels'] = predictions\n",
    "test['Probabilities'] = model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "test.to_csv('./assets/data/transformed_heart_test.csv', index=False)\n",
    "\n",
    "accuracy = accuracy_score(test[target_column], predictions)\n",
    "recall = recall_score(test[target_column], predictions)\n",
    "\n",
    "print({'accuracy': accuracy, 'recall': recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d29375-c2d8-4e25-9b2a-0a83f297c347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./assets/train/xgb.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, './assets/train/xgb.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62129cac-fba4-4217-a039-aeae00b0827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "transformer = joblib.load('./assets/train/col_transformer.pkl')\n",
    "xgbc = joblib.load('./assets/train/xgb.pkl')\n",
    "\n",
    "pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                              ('xgbc', xgbc)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c222175d-e0ac-43bf-a390-339d58035a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;conti_feat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;thalach&#x27;, &#x27;trestbps&#x27;]),\n",
       "                                                 (&#x27;disc_feat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unk...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;conti_feat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;thalach&#x27;, &#x27;trestbps&#x27;]),\n",
       "                                                 (&#x27;disc_feat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unk...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;conti_feat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;thalach&#x27;,\n",
       "                                  &#x27;trestbps&#x27;]),\n",
       "                                (&#x27;disc_feat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=nan))]),\n",
       "                                 [&#x27;ca&#x27;, &#x27;cp&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;,\n",
       "                                  &#x27;slope&#x27;, &#x27;thal&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">conti_feat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;chol&#x27;, &#x27;oldpeak&#x27;, &#x27;thalach&#x27;, &#x27;trestbps&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">disc_feat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ca&#x27;, &#x27;cp&#x27;, &#x27;exang&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;sex&#x27;, &#x27;slope&#x27;, &#x27;thal&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=nan)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(transformers=[('conti_feat_pipeline',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'chol', 'oldpeak',\n",
       "                                                   'thalach', 'trestbps']),\n",
       "                                                 ('disc_feat_pipeline',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OrdinalEncoder(handle_unk...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7967275-1a4e-4fe1-947b-6c93fd68ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4096dde-0878-464f-84c7-c85eacfac656",
   "metadata": {},
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb15ae1e-b7b3-4aa1-a79e-07af0082729d",
   "metadata": {},
   "source": [
    "# ONNX 101\n",
    "\n",
    "<pre>\n",
    "\n",
    "<b>ONNX - Open Neural Network eXchange Format</b>\n",
    "\n",
    "1. Interoperability between many formats like PyTorch, TF and Sklearn\n",
    "2. This gives a variety of functions that converts framework agnostic capabilities\n",
    "3. It is run in an ONNX runtime and on top of any interpreter like Java, Python and etc.\n",
    "4. ONNX produces a computational graph that consists of how the model should be executed\n",
    "5. ONNX operators are for inputs, outputs, Node, initializer and attributes\n",
    "6. Nodes are matrix multiplication, add etc.\n",
    "7. Initializers can be default values\n",
    "8. Attributes are frozen values in an operator like alpha, beta\n",
    "9. Serialization is done through protobuf\n",
    "10. There are 2 domains ai.onnx and ai.onnx.ml. Domains are set of operators available for us. ai.onnx has DL modules while ai.onnx.ml has sklearn related implementations. Custom domains are also possible.\n",
    "11. Tensors in ONNX have a type, shape and are contiguous in memory.\n",
    "12. Element types are data types\n",
    "13. Opset is the version of ONNX package. Every new opset will introduce a new set of operators.\n",
    "14. Converters are used to convert the models into ONNX format.\n",
    "    a. sklearn-onnx: converts models from scikit-learn,\n",
    "    b. tensorflow-onnx: converts models from tensorflow,\n",
    "    c. onnxmltools: converts models from lightgbm, xgboost, pyspark, libsvm\n",
    "    d. torch.onnx: converts model from pytorch.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2f179-4871-4922-8ada-6a5f495bf169",
   "metadata": {},
   "source": [
    "# ONNX Sklearn Definition\n",
    "\n",
    "<pre>\n",
    "\n",
    "1. Define the input types:\n",
    "    Eg. [\n",
    "            ('float_input', FloatTensorType([None, 4])), # We are saying that 4 inputs are float\n",
    "            ('int_input', FloatTensorType([None, 2])) # We are saying that 2 inputs are int\n",
    "    ]\n",
    "2. Convert the model to ONNX format by passing the model and input types\n",
    "3. Using inference session predict the results\n",
    "4. Skl2onnx only supports scikit-learn entities when we have xgboost, lightgbm along with sklearn in the pipeline we have to use onnxmltools to register and use it. If we do not do that it will result in error.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac054104-9563-410f-81ee-f6adf9d8f7f7",
   "metadata": {},
   "source": [
    "Ref : https://onnx.ai/sklearn-onnx/auto_examples/plot_pipeline_xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12aedf1c-7eee-4bec-aedf-0871d7f49538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/algebra/onnx_ops.py:159: UserWarning: OpSchema.FormalParameter.typeStr is deprecated and will be removed in 1.16. Use OpSchema.FormalParameter.type_str instead.\n",
      "  tys = obj.typeStr or ''\n",
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/algebra/automation.py:154: UserWarning: OpSchema.FormalParameter.isHomogeneous is deprecated and will be removed in 1.16. Use OpSchema.FormalParameter.is_homogeneous instead.\n",
      "  if getattr(obj, 'isHomogeneous', False):\n",
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/jinja2/environment.py:485: UserWarning: OpSchema.FormalParameter.typeStr is deprecated and will be removed in 1.16. Use OpSchema.FormalParameter.type_str instead.\n",
      "  return getattr(obj, attribute)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to find column name 'age' among names ['input']. Make sure the input names specified with parameter initial_types fits the column names specified in the pipeline to convert. This may happen because a ColumnTransformer follows a transformer without any mapped converter in a pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskl2onnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect_intermediate_steps, compare_objects\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskl2onnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatTensorType\n\u001b[0;32m----> 5\u001b[0m operators \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_intermediate_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mFloatTensorType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m dummy_data \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m2\u001b[39m,:]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m operators:\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# The ONNX for this operator.\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/helpers/investigate.py:237\u001b[0m, in \u001b[0;36mcollect_intermediate_steps\u001b[0;34m(model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MissingShapeCalculator, MissingConverter\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     model_onnx, topology \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_sklearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (MissingShapeCalculator, MissingConverter):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# The model cannot be converted.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/convert.py:178\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] parse_sklearn_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m topology \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sklearn_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_conversion_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_shape_calculators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhite_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhite_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblack_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblack_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaming\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Convert our Topology object into ONNX. The outcome is an ONNX model.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m options \u001b[38;5;241m=\u001b[39m _process_options(model, options)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/_parse.py:789\u001b[0m, in \u001b[0;36mparse_sklearn_model\u001b[0;34m(model, initial_types, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, white_op, black_op, final_types, naming)\u001b[0m\n\u001b[1;32m    786\u001b[0m     raw_model_container\u001b[38;5;241m.\u001b[39madd_input(variable)\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Parse the input scikit-learn model as a Topology object.\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfinal_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# The object raw_model_container is a part of the topology we're\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# going to return. We use it to store the outputs of the\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# scikit-learn's computational graph.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(final_types) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(outputs):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/_parse.py:709\u001b[0m, in \u001b[0;36mparse_sklearn\u001b[0;34m(scope, model, inputs, custom_parsers, final_types)\u001b[0m\n\u001b[1;32m    706\u001b[0m             o\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m--> 709\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sklearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[1;32m    712\u001b[0m     r\u001b[38;5;241m.\u001b[39minit_status(is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/_parse.py:646\u001b[0m, in \u001b[0;36m_parse_sklearn\u001b[0;34m(scope, model, inputs, custom_parsers, alias)\u001b[0m\n\u001b[1;32m    643\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m custom_parsers[tmodel](scope, model, inputs,\n\u001b[1;32m    644\u001b[0m                                      custom_parsers\u001b[38;5;241m=\u001b[39mcustom_parsers)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tmodel \u001b[38;5;129;01min\u001b[39;00m sklearn_parsers_map:\n\u001b[0;32m--> 646\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43msklearn_parsers_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pipeline\u001b[38;5;241m.\u001b[39mPipeline):\n\u001b[1;32m    649\u001b[0m     parser \u001b[38;5;241m=\u001b[39m sklearn_parsers_map[pipeline\u001b[38;5;241m.\u001b[39mPipeline]\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/_parse.py:273\u001b[0m, in \u001b[0;36m_parse_sklearn_pipeline\u001b[0;34m(scope, model, inputs, custom_parsers)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mThe basic ideas of scikit-learn parsing:\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    1. Sequentially go though all stages defined in the considered\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m:return: A list of output variables produced by the input pipeline\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39msteps:\n\u001b[0;32m--> 273\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/_parse.py:646\u001b[0m, in \u001b[0;36m_parse_sklearn\u001b[0;34m(scope, model, inputs, custom_parsers, alias)\u001b[0m\n\u001b[1;32m    643\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m custom_parsers[tmodel](scope, model, inputs,\n\u001b[1;32m    644\u001b[0m                                      custom_parsers\u001b[38;5;241m=\u001b[39mcustom_parsers)\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tmodel \u001b[38;5;129;01min\u001b[39;00m sklearn_parsers_map:\n\u001b[0;32m--> 646\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43msklearn_parsers_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pipeline\u001b[38;5;241m.\u001b[39mPipeline):\n\u001b[1;32m    649\u001b[0m     parser \u001b[38;5;241m=\u001b[39m sklearn_parsers_map[pipeline\u001b[38;5;241m.\u001b[39mPipeline]\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/_parse.py:339\u001b[0m, in \u001b[0;36m_parse_sklearn_column_transformer\u001b[0;34m(scope, model, inputs, custom_parsers)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(column_indices, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m    338\u001b[0m     column_indices \u001b[38;5;241m=\u001b[39m [column_indices]\n\u001b[0;32m--> 339\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[43mget_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m transform_inputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m onnx_var, onnx_is \u001b[38;5;129;01min\u001b[39;00m names\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/common/utils.py:137\u001b[0m, in \u001b[0;36mget_column_indices\u001b[0;34m(indices, inputs, multiple)\u001b[0m\n\u001b[1;32m    135\u001b[0m res \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[0;32m--> 137\u001b[0m     ov, onnx_i \u001b[38;5;241m=\u001b[39m \u001b[43mget_column_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ov \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[1;32m    139\u001b[0m         res[ov] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/skl2onnx/common/utils.py:111\u001b[0m, in \u001b[0;36mget_column_index\u001b[0;34m(i, inputs)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mraw_name \u001b[38;5;241m==\u001b[39m i:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ind, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find column name \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m among names \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure the input names specified with parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_types fits the column names specified in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline to convert. This may happen because a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer follows a transformer without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many mapped converter in a pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    118\u001b[0m         i, [n\u001b[38;5;241m.\u001b[39mraw_name \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m inputs]))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to find column name 'age' among names ['input']. Make sure the input names specified with parameter initial_types fits the column names specified in the pipeline to convert. This may happen because a ColumnTransformer follows a transformer without any mapped converter in a pipeline."
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "from skl2onnx.helpers import collect_intermediate_steps, compare_objects\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "operators = collect_intermediate_steps(pipeline, \"pipeline\", [(\"input\",\n",
    "                                         FloatTensorType([None, len(train_features.columns)]))])\n",
    "dummy_data = train.iloc[:2,:].to_numpy()\n",
    "\n",
    "for op in operators:\n",
    "\n",
    "    # The ONNX for this operator.\n",
    "    onnx_step = op['onnx_step']\n",
    "\n",
    "    # Use onnxruntime to compute ONNX outputs\n",
    "    sess = onnxruntime.InferenceSession(onnx_step.SerializeToString(),\n",
    "                                        providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    # Let's use the initial data as the ONNX model\n",
    "    # contains all nodes from the first inputs to this node.\n",
    "    onnx_outputs = sess.run(None, {'input': data})\n",
    "    onnx_output = onnx_outputs[0]\n",
    "    skl_outputs = op['model']._debug.outputs['transform']\n",
    "\n",
    "    # Compares the outputs between scikit-learn and onnxruntime.\n",
    "    assert_almost_equal(onnx_output, skl_outputs)\n",
    "\n",
    "    # A function which is able to deal with different types.\n",
    "    compare_objects(onnx_output, skl_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9b07683-a764-4caf-924f-5afe9a895cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skl2onnx\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\n",
    "import onnxmltools\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost  # noqa\n",
    "import onnxmltools.convert.common.data_types\n",
    "\n",
    "skl2onnx.update_registered_converter(XGBClassifier, 'XGBoostXGBClassifier',\n",
    "    calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3c090b-a6f2-4a4b-93b7-81f78ce2d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_schema(df, drop=None):\n",
    "    inputs = []\n",
    "    for k, v in zip(df.columns, df.dtypes):\n",
    "        if drop is not None and k in drop:\n",
    "            continue\n",
    "        if v == 'int64':\n",
    "            t = Int64TensorType([None, 1])\n",
    "        elif v == 'float64':\n",
    "            t = FloatTensorType([None, 1])\n",
    "        else:\n",
    "            t = StringTensorType([None, 1])\n",
    "        inputs.append((k, t))\n",
    "    return inputs\n",
    "\n",
    "input_types = convert_dataframe_schema(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd5e0b7a-1d6b-4f5d-b33f-61005b034307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onnx = skl2onnx.convert_sklearn(\n",
    "    pipeline, 'pipeline_heart_classification',\n",
    "    input_types,\n",
    "    target_opset = {'': 12, 'ai.onnx.ml': 2})\n",
    "\n",
    "# And save.\n",
    "with open(f'{TRAIN_DIR}/pipeline_xgboost.onnx', 'wb') as f:\n",
    "    f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d17246a3-ecf5-48db-9b81-93abaa84e4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', FloatTensorType(shape=[None, 1])),\n",
       " ('chol', FloatTensorType(shape=[None, 1])),\n",
       " ('oldpeak', FloatTensorType(shape=[None, 1])),\n",
       " ('thalach', FloatTensorType(shape=[None, 1])),\n",
       " ('trestbps', FloatTensorType(shape=[None, 1])),\n",
       " ('ca', FloatTensorType(shape=[None, 1])),\n",
       " ('cp', FloatTensorType(shape=[None, 1])),\n",
       " ('exang', FloatTensorType(shape=[None, 1])),\n",
       " ('fbs', FloatTensorType(shape=[None, 1])),\n",
       " ('restecg', FloatTensorType(shape=[None, 1])),\n",
       " ('sex', FloatTensorType(shape=[None, 1])),\n",
       " ('slope', FloatTensorType(shape=[None, 1])),\n",
       " ('thal', FloatTensorType(shape=[None, 1]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f06d5578-b896-447c-b9a6-d734ede2d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(f'{TRAIN_DIR}/pipeline_xgboost.onnx',\n",
    "                           providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f62a40-c683-46e5-a48e-91303ff1acd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_create_inference_session',\n",
       " '_enable_fallback',\n",
       " '_fallback_providers',\n",
       " '_inputs_meta',\n",
       " '_model_bytes',\n",
       " '_model_meta',\n",
       " '_model_path',\n",
       " '_outputs_meta',\n",
       " '_overridable_initializers',\n",
       " '_profiling_start_time_ns',\n",
       " '_provider_options',\n",
       " '_providers',\n",
       " '_read_config_from_model',\n",
       " '_reset_session',\n",
       " '_sess',\n",
       " '_sess_options',\n",
       " '_sess_options_initial',\n",
       " '_validate_input',\n",
       " 'disable_fallback',\n",
       " 'enable_fallback',\n",
       " 'end_profiling',\n",
       " 'get_inputs',\n",
       " 'get_modelmeta',\n",
       " 'get_outputs',\n",
       " 'get_overridable_initializers',\n",
       " 'get_profiling_start_time_ns',\n",
       " 'get_provider_options',\n",
       " 'get_providers',\n",
       " 'get_session_options',\n",
       " 'get_tuning_results',\n",
       " 'io_binding',\n",
       " 'run',\n",
       " 'run_with_iobinding',\n",
       " 'run_with_ort_values',\n",
       " 'run_with_ortvaluevector',\n",
       " 'set_providers',\n",
       " 'set_tuning_results']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a787159c-239a-41cc-bd0e-405ba11a3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c79ae4b0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c79888f0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798bab0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798bfb0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798bf30>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c7988df0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798a4b0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798be30>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798a030>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798a1b0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c7989930>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c7988570>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798b530>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4c4a064-33ff-42f3-bf07-7ac156298f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'name',\n",
       " 'shape',\n",
       " 'type']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sess.get_inputs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ab2c9b1-5ed6-4d60-ab4b-7fe204b12320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c7989770>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7fb6c798b6b0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3268077b-d7ca-47dd-a8ad-895f01736535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'name',\n",
       " 'shape',\n",
       " 'type']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sess.get_outputs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8ebda54-d481-4108-932d-d793cbaaaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {c: test_features[c].values for c in test_features.columns}\n",
    "for c in test_features.columns:\n",
    "    inputs[c] = inputs[c].astype(np.float32)\n",
    "for k in inputs:\n",
    "    inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1faa2dfc-3f28-4a6e-a28c-de587aa545da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx = sess.run(None, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e15f1a4-d711-4d5e-9d3a-154748cef7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82274705],\n",
       "       [-0.28818145],\n",
       "       [ 0.4894685 ],\n",
       "       [ 0.15618995],\n",
       "       [-1.9545742 ],\n",
       "       [-0.1770886 ],\n",
       "       [ 1.2671185 ],\n",
       "       [ 0.15618995],\n",
       "       [ 0.9338399 ],\n",
       "       [ 0.37837565],\n",
       "       [ 0.9338399 ],\n",
       "       [-2.843317  ],\n",
       "       [ 0.0450971 ],\n",
       "       [ 0.37837565],\n",
       "       [ 0.82274705],\n",
       "       [-1.5102028 ],\n",
       "       [-1.5102028 ],\n",
       "       [-1.0658314 ],\n",
       "       [ 0.4894685 ],\n",
       "       [-1.0658314 ],\n",
       "       [ 0.4894685 ],\n",
       "       [ 1.4893042 ],\n",
       "       [-1.5102028 ],\n",
       "       [-0.7325528 ],\n",
       "       [ 0.4894685 ],\n",
       "       [-1.39911   ],\n",
       "       [-1.1769242 ],\n",
       "       [-0.3992743 ],\n",
       "       [-1.1769242 ],\n",
       "       [ 0.7116542 ],\n",
       "       [ 0.26728278],\n",
       "       [ 0.9338399 ],\n",
       "       [-1.1769242 ],\n",
       "       [-0.06599575],\n",
       "       [-0.62146   ],\n",
       "       [-1.6212957 ],\n",
       "       [-1.5102028 ],\n",
       "       [-0.7325528 ],\n",
       "       [-1.39911   ],\n",
       "       [ 0.0450971 ],\n",
       "       [ 0.15618995],\n",
       "       [-0.3992743 ],\n",
       "       [-1.1769242 ],\n",
       "       [-0.7325528 ],\n",
       "       [ 0.37837565],\n",
       "       [ 1.0449327 ],\n",
       "       [ 0.26728278],\n",
       "       [-0.62146   ],\n",
       "       [-1.1769242 ],\n",
       "       [-0.3992743 ],\n",
       "       [-1.5102028 ],\n",
       "       [ 1.1560256 ],\n",
       "       [ 0.26728278],\n",
       "       [-1.2880172 ],\n",
       "       [ 0.0450971 ],\n",
       "       [ 0.6005613 ],\n",
       "       [-1.7323885 ],\n",
       "       [ 1.0449327 ],\n",
       "       [ 1.8225827 ],\n",
       "       [-0.06599575],\n",
       "       [-1.5102028 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['age'] #This is how the input looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faf1567b-d553-4907-82ca-aa151d1ac315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pred_onx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39fb98e7-720b-41f4-ae8d-a3602a06b59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_onx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18c84a8d-e18f-453c-a154-be0647bfafdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_onx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4c5233-940b-4e08-adee-5b8e76e8dade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad4058-4e7b-41bf-b0b3-fc18c1ae1b63",
   "metadata": {},
   "source": [
    "## Creating an online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7910cca5-2236-424e-ac94-c8f69e2c7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf4f1267-524a-4c8c-b4fe-4aff40f4375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'heart-onnx-16-6'\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name = endpoint_name,\n",
    "    description = 'this is a sample online endpoint',\n",
    "    auth_mode = 'key',\n",
    "    tags = {'env': 'test'},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd5526-8afd-4a14-b78a-0ad4f79d08f2",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "<b> The following things are required to host the model on AML Endpoint </b>\n",
    "\n",
    "> Model files - here it is an ONNX file\n",
    "> Scoring script - how do we want to predict/evaluate the incoming data. Score.py is the default filename\n",
    "> Environment - A custom environment which runs on docker\n",
    "> Settings - Related to compute etc.\n",
    "> EndpointName - The name of the endpoint where the pipeline is hosted\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e6bdf7f-0d4e-409f-a857-c31fa780df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing assets/env/conda_definition.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {ENV_DIR}/conda_definition.yml\n",
    "\n",
    "name: heart-env\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.10\n",
    "- pip\n",
    "- pip:\n",
    "  - pandas==2.0.2\n",
    "  - numpy==1.24.3\n",
    "  - onnxruntime==1.15.0\n",
    "  - inference-schema==1.5.1\n",
    "  - azureml-inference-server-http==0.8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06273823-f36d-40bb-83f9-96d99625d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path = './assets/train/pipeline_xgboost.onnx')\n",
    "env = Environment(\n",
    "    conda_file=\"./assets/env/conda_definition.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38963b2b-6620-4513-82f8-4ab9196b4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = ws.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0fd448a-cd7b-4ccd-a747-00d4a2f7e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ws.online_endpoints.get_keys(endpoint_name).primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e55a6244-d51c-40a3-8906-bb74589017c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting assets/deployment/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DEPLOYMENT_DIR}/score.py\n",
    "\n",
    "#Writing inference schema to generate Swagger documentation automatically\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import (\n",
    "    StandardPythonParameterType,\n",
    ")\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import onnxruntime as rt\n",
    "\n",
    "model = None\n",
    "targets = np.array(['Yes', 'No'])\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global ip_features\n",
    "    model_dir = os.getenv('AZUREML_MODEL_DIR', '')\n",
    "    model_path = os.path.join(model_dir, 'pipeline_xgboost.onnx')\n",
    "    model = rt.InferenceSession(model_path,\n",
    "                           providers=[\"CPUExecutionProvider\"])\n",
    "    ip_features = ['age', 'chol', 'oldpeak', 'thalach', 'trestbps', 'ca', 'cp', 'exang',\n",
    "       'fbs', 'restecg', 'sex', 'slope', 'thal']\n",
    "\n",
    "@input_schema(\n",
    "    param_name = 'data', param_type = NumpyParameterType(np.array([[ 0.15618995, 0.79578295, 2.52965595, -0.70000655,  3.84978957,2., 4.,  1.,  1.,  2.,0.,  2.,  4.]]))\n",
    ")\n",
    "@output_schema(output_type=StandardPythonParameterType({'Disease': ['Yes']}))\n",
    "def run(data):\n",
    "    \n",
    "    logging.info(type(data))\n",
    "    \n",
    "    inputs = {column : [] for column in ip_features}\n",
    "    for row in data:\n",
    "        for index, col in enumerate(ip_features):\n",
    "            inputs[col].append(row[index])\n",
    "    \n",
    "    for c in ip_features:\n",
    "        inputs[c] = np.array(inputs[c]).astype(np.float32)\n",
    "        \n",
    "    for k in inputs:\n",
    "        inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))\n",
    "    pred_onx = model.run(None, inputs)\n",
    "    predicted_categories = np.choose(pred_onx[0], targets).flatten()\n",
    "    result = {\n",
    "        \"Disease\": predicted_categories.tolist(),\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d21d0b05-051f-4bea-9443-220a5a983dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name = 'blue',\n",
    "    endpoint_name = endpoint_name,\n",
    "    model = model,\n",
    "    environment = env,\n",
    "    code_configuration = CodeConfiguration(\n",
    "        code = './assets/deployment', scoring_script = 'score.py'\n",
    "    ),\n",
    "    instance_type='Standard_DS1_v2',\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4073ca68-77e5-4cb6-affc-abb72fd97f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instance type Standard_DS1_v2 may be too small for compute resources. Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: https://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\n",
      "Check: endpoint heart-onnx-16-6 exists\n",
      "\u001b[32mUploading deployment (0.0 MBs): 100%|██████████| 1743/1743 [00:00<00:00, 106732.93it/s]\n",
      "\u001b[39m\n",
      "\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................."
     ]
    }
   ],
   "source": [
    "deployment = ws.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9a3bb07-2012-40f8-b379-4aa9560aa708",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_deployment = ws.online_deployments.get(\n",
    "    name=\"blue\", endpoint_name = endpoint_name\n",
    ")\n",
    "##--Scaling the deployment--##\n",
    "#blue_deployment.instance_count = 2\n",
    "#ws.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25ff3b21-e1ff-4f59-8766-43c54104b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "https://heart-onnx-16-6.eastus2.inference.ml.azure.com/score\n"
     ]
    }
   ],
   "source": [
    "print(endpoint.traffic)\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d464f6c-36d9-4bd6-8881-eaf3fad6441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Green deployments should be different but in our case we are taking the same code\n",
    "\n",
    "green_deployment = ManagedOnlineDeployment(\n",
    "    name = 'green',\n",
    "    endpoint_name = endpoint_name,\n",
    "    model = model,\n",
    "    environment = env,\n",
    "    code_configuration = CodeConfiguration(\n",
    "        code = './assets/deployment', scoring_script = 'score.py'\n",
    "    ),\n",
    "    instance_type='Standard_DS1_v2',\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c7b7da1-09c9-4e63-936a-d8a8957764de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instance type Standard_DS1_v2 may be too small for compute resources. Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: https://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\n",
      "Check: endpoint heart-onnx-16-6 exists\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineDeployment({'private_network_connection': False, 'provisioning_state': 'Succeeded', 'data_collector': None, 'endpoint_name': 'heart-onnx-16-6', 'type': 'Managed', 'name': 'green', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/0cfe2870-d256-4119-b0a3-16293ac11bdc/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/od:b1b80a69-b296-4608-92a4-33acdff57c2e:13b04c38-768d-4e71-b095-68eb12a2ace1?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/0cfe2870-d256-4119-b0a3-16293ac11bdc/resourceGroups/1-2ba149fb-playground-sandbox/providers/Microsoft.MachineLearningServices/workspaces/MLOPS101/onlineEndpoints/heart-onnx-16-6/deployments/green', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops101x/code/Users/cloud_user_p_b28104ff', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fb6c62653f0>, 'model': '/subscriptions/0cfe2870-d256-4119-b0a3-16293ac11bdc/resourceGroups/1-2ba149fb-playground-sandbox/providers/Microsoft.MachineLearningServices/workspaces/MLOPS101/models/48fbd7c6c90f1008fb255bffc74148cc/versions/1', 'code_configuration': {'code': '/subscriptions/0cfe2870-d256-4119-b0a3-16293ac11bdc/resourceGroups/1-2ba149fb-playground-sandbox/providers/Microsoft.MachineLearningServices/workspaces/MLOPS101/codes/fecb3361-7d93-4c14-842a-37303580f79b/versions/1'}, 'environment': '/subscriptions/0cfe2870-d256-4119-b0a3-16293ac11bdc/resourceGroups/1-2ba149fb-playground-sandbox/providers/Microsoft.MachineLearningServices/workspaces/MLOPS101/environments/CliV2AnonymousEnvironment/versions/dbee7b39849a36dc345eb6d8e9c3da31', 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7fb6c6265c00>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7fb6c6265870>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fb6c6265ab0>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fb6c6265750>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_DS1_v2', 'egress_public_network_access': 'Enabled'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.online_deployments.begin_create_or_update(green_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7f4ec9f-51b0-4827-b77b-f030319fb561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.json\n",
    "\n",
    "{\n",
    "  \"data\": [\n",
    "    [\n",
    "      0.15618995,\n",
    "      0.79578295,\n",
    "      2.52965595,\n",
    "      -0.70000655,\n",
    "      3.84978957,\n",
    "      2,\n",
    "      4,\n",
    "      1,\n",
    "      1,\n",
    "      2,\n",
    "      0,\n",
    "      2,\n",
    "      4\n",
    "    ]\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d5b209e-0abe-4f64-890a-307a564042ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Disease\": [\"No\"]}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.online_endpoints.invoke(\n",
    "    endpoint_name = endpoint_name,\n",
    "    deployment_name = 'green',\n",
    "    request_file = 'test.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aba1e0-7178-459b-a16f-bdb28582c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.traffic = {'blue': 90, 'green' : 10}\n",
    "ws.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0399ebaa-bd65-42db-9e8a-69f158854489",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.online_deployments.begin_delete(\n",
    "    name = 'blue', endpoint_name = endpoint_name\n",
    ").wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83930c-0997-4951-a3f0-50728de52898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
